
\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}

\title{CS 288: Machine Translation}

\author{Anting Shen \\
  23566738 \\
  {\tt antingshen@berkeley.edu} \\
}
\date{October 17, 2014}

\begin{document}
\maketitle

\section{Introduction}


\section{Heuristic Aligner}

As a heuristic aligner, I chose to score alignments using ratio of counts. Each French word
is aligned to the highest scoring English word. Training size is set at 10,000.
At first, I tried scoring $S = c(e, f) / (c(e) \cdot c(f))$, but this performed worse than the
baseline aligner. Tweaking the formula to $S = c(e, f) / (c(e) + c(f))$, AER improved to 58.3%
and BLEU improved to 12.421. Scoring using normalized counts (count divided by total) drops
performance to 58.5% AER and 12.208 BLEU, so this change was reverted.

Building this aligner with 10,000 sentences takes 1 second. Increasing training size to 100,000
decreases AER to 46.1%, increases time to 23 seconds, and BLEU to 17.270. Further increasing
size to 200,000 decreases AER to 44%, and increases time to 2 minutes 52 seconds. Phrase table
took too long to build with this data size so BLEU was not computed.

\section{Model 1 Aligner}

My first model 1 implementation uses 100 iterations of soft-EM. It uses a counter to store
probabilities, and a new counter is created each iteration and is filled using probabilities
calculated from values from the previous iteration. It is not intersected, trains in 2m31s
using 803M memory, and achieves AER of 38.3% and BLEU of 15.795 on the size 10,000 set.

Precision: 0.5569471624266145
Recall: 0.7308073303615651





\end{document}
