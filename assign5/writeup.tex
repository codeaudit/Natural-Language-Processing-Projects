
\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}

\title{CS 288: Machine Translation}

\author{Anting Shen \\
  23566738 \\
  {\tt antingshen@berkeley.edu} \\
}
\date{October 17, 2014}

\begin{document}
\maketitle

\section{Introduction}


\section{Heuristic Aligner}

As a heuristic aligner, I chose to score alignments using ratio of counts. Each French word
is aligned to the highest scoring English word. Training size is set at 10,000.
At first, I tried scoring $S = c(e, f) / (c(e) \cdot c(f))$, but this performed worse than the
baseline aligner. Tweaking the formula to $S = c(e, f) / (c(e) + c(f))$, AER improved to 58.3%
and BLEU improved to 12.421. Scoring using normalized counts (count divided by total) drops
performance to 58.5% AER and 12.208 BLEU, so this change was reverted.

Building this aligner with 10,000 sentences takes 1 second. Increasing training size to 100,000
decreases AER to 46.1%, increases time to 23 seconds, and BLEU to 17.270. Further increasing
size to 200,000 decreases AER to 44%, and increases time to 2 minutes 52 seconds. Phrase table
took too long to build with this data size so BLEU was not computed.

\section{Model 1 Aligner}

My first model 1 implementation uses 100 iterations of soft-EM. It uses a counter to store
probabilities, and a new counter is created each iteration and is filled using probabilities
calculated from values from the previous iteration. Null is handled by appending a null word to
the beginning of each English sentence and ignoring null alignments in the output.
It is not intersected, trains in 2m31s using 803M memory, and achieves AER of 38.3%
and BLEU of 15.795 on the size 10,000 set.

Using an intersected model instead, where the model only predicts alignments that are found by
aligners in both directions, precision increased from 0.56 to 0.84, while recall decreased from
0.73 to 0.63. This was expected as the intersected model predicts a sparser alignment.
Interestingly, AER and BLEU both decreased to 27.4% and 13.2, respectively. This shows that
improvements in AER do not always increase BLEU, perhaps due to the translation system
not working as well using sparser alignments. The intersected model also doubles training time
to 5m5s to train both models in both directions.

\section{HMM Aligner}

Precision: 0.9338727678571429
Recall: 0.7147102526002972
AER: 0.1822356336919444
		Arrays.fill(transitions, 0.2);
		transitions[-1 + MAX_TRANSITION] += 0.1;
		transitions[0 + MAX_TRANSITION] += 0.5;
		transitions[1 + MAX_TRANSITION] += 4;
		transitions[2 + MAX_TRANSITION] += 0.5;
		transitions[3 + MAX_TRANSITION] += 0.1;

\end{document}
