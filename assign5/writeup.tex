
\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}

\title{CS 288: Machine Translation}

\author{Anting Shen \\
  23566738 \\
  {\tt antingshen@berkeley.edu} \\
}
\date{October 17, 2014}

\begin{document}
\maketitle

\section{Introduction}


\section{Heuristic Aligner}

As a heuristic aligner, I chose to score alignments using ratio of counts. Each French word
is aligned to the highest scoring English word. Training size is set at 10,000.
At first, I tried scoring $S = c(e, f) / (c(e) \cdot c(f))$, but this performed worse than the
baseline aligner. Tweaking the formula to $S = c(e, f) / (c(e) + c(f))$, AER improved to 58.3%
and BLEU improved to 12.421. Scoring using normalized counts (count divided by total) drops
performance to 58.5% AER and 12.208 BLEU, so this change was reverted.

Building this aligner with 10,000 sentences takes 1 second. Increasing training size to 100,000
decreases AER to 46.1%, increases time to 23 seconds, and BLEU to 17.270. Further increasing
size to 200,000 decreases AER to 44%, and increases time to 2 minutes 52 seconds. Phrase table
took too long to build with this data size so BLEU was not computed.

\section{Model 1 Aligner}





\end{document}
