
\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}

\title{CS 288: Parsing}

\author{Anting Shen \\
  23566738 \\
  {\tt antingshen@berkeley.edu} \\
}
\date{October 17, 2014}

\begin{document}
\maketitle


\section{Generative Parser}

The generative parser uses a straightforward CKY algorithm. A grammar
(from the provided Grammar class) is generated from annotated
trees and a UnaryClosure class is used to collapse and re-expand chains of unary rules to allow
application of a binary rule at every other step to prevent infinite unary chains. Each unary
step also enforces addition of a reflexive rule to indicate a lack of unary rule at that step.

The tree annotator uses $v=2, h=2$ vertical and horizontal markovization, which showed considerable
F1 improvement over the $v=1, h=\infty$ default, with most of the improvement being from the
switch from $v=1$ to $v=2$, and a smaller improvement from $h=\infty$ to $h=2$.

The CKY tables needed for bottom-up CKY are implemented as three dimensional double arrays, one for
unary and one for binary, and with the array being triangular instead of square to prevent memory
waste. Backpointers are kept in a separate same sized array to save memory of
creating a wrapper object and provide memory locality when performing score lookups. Backpointers
consist of the rule used at that cell, and the split point $k$ for binary rules. Helper functions
recursively reconstruct the tree at the end of parsing, expanding UnaryClosures and ignoring reflexive
rules.

With this implementation on the max length 40 data set, the parser achieves an F1 of 79.0
in 27 minutes on an i5-4670 processor.

\section{Coarse to Fine Parser}

The inside-outside algorithm is used to calculate probabilities of trees in the coarse grammar.
A cell in the fine grammar's table is filled with negative infinity if the corresponding probability
in the coarse grammar is below a threshold. The probability is calculated by
$I(x,i,j)+O(x,i,j)-I(0,0,0)$, where $I$ and $O$ are inside and outside log probabilities, calculated
using max instead of sum as an estimate due to difficulty of summing log probabilities.
To find the corresponding coarse tag from a fine tag, a precomputed indexed mapping array is used.
The coarse grammar is $v=1, h=0$, and its CKY tables are additional multidimensional arrays.

Manual binary search was used to find a balanced threshold between F1 and speed at a log
probability of -7.
The parser achieves on the 40 length set a F1 of 78.53 in 751 seconds on the same processor,
for a 2.16x speed-up.

\section{Additional Optimizations}
This section includes additional exploration and optimizations of both accuracy and performance.
These optimizations are only for the coarse to fine parser and are not back ported to the
generative parser.

\subsection{Increasing Vertical Markovization Order}
Klein and Manning 03 suggests that increased vertical order produces better F1, so grandparent
annotations were added to increase $v$ to 3. On the length 40 set, this increased F1 to 79.93
at a cost of increasing running time to 932 seconds due to a large increase in grammar size.
However, the amount of time did not increase as much relative to the grammar size thanks to
coarse to fine pruning.

\subsection{Collapsing Sparse Grammar Rules}
With increased Markovization order and increased number of grammar rules, many rules have only been
seen a small number of times. Following Klein and Manning, the grammar was modified to only split
rules horizontally if it has been seen at least 10 times. Rules are still always split vertically.
This gives a new Markovization order of $h\leq 2$. With this improvement, F1 increased to 80.0
and the reduced number of grammar rules cut the running time back down to 749 seconds.

\subsection{Additional Annotations}
Many of the remaining mistakes are caused by the grammar using the same tag for different contexts
that should get their own tag. To address this, more annotations are added to produce a finer grammar.
First, the \texttt{UNARY-INTERNAL} mark was added to non-preterminal non-root unary nodes,
which increased F1 to 80.52 and reduced running time to 687 seconds. Adding \texttt{UNARY-RB} and
\texttt{UNARY-DT} further improved F1 to 80.81 and cut time to 634 seconds.

Splitting tags seemed like another possible addition. When \texttt{IN} tags were directly
annotated with their respective words, i.e. lexicalized, F1 increased to 80.93, and time increased to
740 seconds. However, this method splits the \texttt{IN} tag 170 different ways. A better approach
would be to split based on linguistic categories like in Klein and Manning 03,
but the does not explain in detail how \texttt{IN} tags were split. When I experimented with
annotating with case-insensitive words to bring the split down to 97-way, F1 stayed at 80.91
while time increased to 826 seconds. Then I experimented with splitting the words into groups
such as prepositions and subordinating conjuctions, which resulted in a F1 of 80.89 and a time of
683 seconds. The lackluster accuracy gain of tag splitting is most likely due to mistakes in
categorizing the words, and getting better performance would require more linguistics experience.



\end{document}
